{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous avons mis en place un modèle de Machine Learning pour la classification d'électrocardiogrammes.\n",
    "Le jeu données utilisé est disponible via [OpenML](https://www.openml.org/search?type=data&status=active&sort=runs&id=44793)\n",
    "\n",
    "L'exécution de la dernière cellule du notebook sauvegarde le modèle former dans le sous-dossier predictions_app/model du dossier de l'application de prédiction développée à l'aide du micro framework Flask.\n",
    "\n",
    "Le démarrage de l'application de prédictions est relativement simple:\n",
    "\n",
    "_Pour la première exécution:_\n",
    "- [créer un environnement virtuel](https://docs.python.org/fr/3/tutorial/venv.html) dans le dossier predictions_app et l'activer\n",
    "- installer les différents packages à l'aide la commande (venv)..\\predictions_app > pip install -r requirements.txt\n",
    "\n",
    "_Pour les prochaines exécutions:_\n",
    "- activer l'environnement virtuel\n",
    "- exécuter la commande > python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des packages (librairies)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du jeu de données\n",
    "filepath = \"datas/dataset.csv\"\n",
    "dataf_ecg = pd.read_csv(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration de notre jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des 5 première observations (lignes)\n",
    "dataf_ecg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage des 5 dernières observations (lignes)\n",
    "dataf_ecg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage (nombre de lignes, nombre de colonnes)\n",
    "dataf_ecg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apreçu graphique des (10) dix premières lignes de données\n",
    "data = dataf_ecg.iloc[:,0:140]\n",
    "abscisses = np.arange(140)\n",
    "fig, axs = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(10, 10))\n",
    "ligne = 0\n",
    "for j in range(5):\n",
    "    for k in range(2):\n",
    "        ecg = \"ECG-LIGNE\" + str(ligne)\n",
    "        axs[j, k].plot(abscisses, data.iloc[ligne], label=ecg, color='red')\n",
    "        axs[j, k].legend()\n",
    "        axs[j, k].grid(True)\n",
    "        ligne = ligne + 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage du résumé statistque\n",
    "dataf_ecg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le jeu de données a-t-elle une distribution équilibrée ?\n",
    "dataf_ecg.groupby('class').size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-traitement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La colonne de variable catégorique déjà encodé"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pas de données manquantes dans notre jeu de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données (mise à l'échelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation (par le test Z )\n",
    "# Créer la matrice de données\n",
    "X = dataf_ecg.iloc[:,:-1].values\n",
    "# Créer le vecteur d'étiquettes\n",
    "y = dataf_ecg.iloc[:,-1].values\n",
    "# Séparation du jeu de données en train et test\n",
    "# 25% des données pour le test et 75% pour l'entrainement\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "# Normalisation des données\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train_normalized = sc_X.fit_transform(X_train)\n",
    "X_test_normalized = sc_X.fit_transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainements, tests et choit de l'algorithme pour le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des métrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSION LOGISTIQUE\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "reg = 0.01\n",
    "modelLogisticRegression= LogisticRegression(C=1/reg, solver='liblinear', max_iter=1000).fit(X_train_normalized, y_train)\n",
    "predictions = modelLogisticRegression.predict(X_test_normalized)\n",
    "# print(\"Étiquettes prédites: \", predictions) \n",
    "# print(\"Étiquettes réelles: \", y_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "print(\"Rapport de classification:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARBRE DE DECISION\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "modelDecisionTree = DecisionTreeClassifier().fit(X_train_normalized, y_train)\n",
    "predictions = modelDecisionTree.predict(X_test_normalized)\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "print(\"\\nRapport de classification:\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine vecteurs de supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHINE A VECTEURS DE SUPORTS\n",
    "from sklearn.svm import SVC\n",
    "modelSVC = SVC(gamma='auto').fit(X_train_normalized, y_train)\n",
    "predictions = modelSVC.predict(X_test_normalized)\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "print(\"Rapport de classification:\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K PLUS PROCHES VOISINS\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "modelKNeighbors = KNeighborsClassifier().fit(X_train_normalized, y_train)\n",
    "predictions = modelKNeighbors.predict(X_test_normalized)\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "print(\"Rapport de classification:\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forêts aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORETS ALEATOIRES\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "modelRandomForest = RandomForestClassifier().fit(X_train_normalized, y_train)\n",
    "predictions = modelRandomForest.predict(X_test_normalized)\n",
    "print('Accuracy: ', accuracy_score(y_test, predictions))\n",
    "print(\"Rapport de classification:\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle\n",
    "import pickle\n",
    "pickle.dump(modelRandomForest, open('predictions_app/model/modelRandomForest.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
